# @title æ•°æ®é›†å¯è§†åŒ–åˆ†æžï¼ˆåŸºäºŽ LDA ä¸»é¢˜ + æƒ…æ„Ÿåˆ†æ•°ï¼‰
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb
from wordcloud import WordCloud
import matplotlib.colors as mcolors
from collections import Counter

# ç»§ç»­ä½¿ç”¨æ— GUIåŽç«¯ï¼ˆä¿å­˜å›¾ç‰‡ï¼‰
import matplotlib

matplotlib.use('Agg')

# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆé¿å…ä¸­æ–‡ä¹±ç ï¼ŒWindowsç³»ç»Ÿï¼‰- ä¿ç•™ä»¥å…¼å®¹å¯èƒ½çš„ä¸­æ–‡å…³é”®è¯ï¼Œä¸å½±å“è‹±æ–‡æ ‡ç­¾
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']  # SimHei=é»‘ä½“ï¼Œå…¼å®¹ä¸­æ–‡å’Œè‹±æ–‡
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

# ===================== 1. åŠ è½½æ•°æ®å’Œå¿…è¦æ¨¡åž‹ =====================
# åŠ è½½æœ€ç»ˆæ•°æ®é›†
df = pd.read_pickle('full_data_with_topic_sentiment.pkl')
print(f"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸï¼Œå…± {len(df)} æ¡æ•°æ®")

# åŠ è½½ LDA æ¨¡åž‹å’Œ TF-IDF å‘é‡å™¨ï¼ˆèŽ·å–ä¸»é¢˜å…³é”®è¯ï¼‰
import joblib

lda = joblib.load('lda_topic_model.pkl')
vectorizer = joblib.load('tfidf_vectorizer.pkl')
feature_names = vectorizer.get_feature_names_out()

# é¢„å®šä¹‰æƒ…æ„Ÿæžæ€§æ ‡ç­¾ï¼ˆæ²¿ç”¨ä¹‹å‰çš„åˆ’åˆ†æ ‡å‡†ï¼‰
df['sentiment_polarity'] = df['sentiment_compound'].apply(
    lambda x: 'positive' if x > 0.05 else ('negative' if x < -0.05 else 'neutral')
)

# èŽ·å–æ¯ä¸ªä¸»é¢˜çš„Top10å…³é”®è¯ï¼ˆç”¨äºŽå›¾è¡¨æ ‡æ³¨ï¼‰
topic_keywords = {}
for topic_idx, topic in enumerate(lda.components_):
    top_words = [feature_names[i] for i in topic.argsort()[:-11:-1]]  # Top10è¯
    topic_keywords[topic_idx] = ', '.join(top_words[:5])  # æ¯ä¸ªä¸»é¢˜æ˜¾ç¤ºå‰5ä¸ªå…³é”®è¯

print(f"\n=== ä¸»é¢˜å…³é”®è¯å¯¹ç…§è¡¨ ===")
for topic_id, keywords in topic_keywords.items():
    print(f"ä¸»é¢˜ {topic_id}: {keywords}")


# ===================== 2. å¯è§†åŒ–å‡½æ•°å®šä¹‰ï¼ˆæ¨¡å—åŒ–ï¼‰ =====================
def plot_topic_distribution():
    """1. LDA ä¸»é¢˜åˆ†å¸ƒï¼ˆé¥¼å›¾ + æ¡å½¢å›¾ï¼‰"""
    topic_counts = df['lda_topic'].value_counts().sort_index()
    topic_labels = [f"topic {i}\n({topic_keywords[i]})" for i in topic_counts.index]

    # å­å›¾ï¼šé¥¼å›¾ï¼ˆå æ¯”ï¼‰+ æ¡å½¢å›¾ï¼ˆæ•°é‡ï¼‰
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

    # é¥¼å›¾
    colors = plt.cm.Set3(np.linspace(0, 1, len(topic_counts)))
    wedges, texts, autotexts = ax1.pie(
        topic_counts.values, labels=topic_labels, autopct='%1.1f%%',
        colors=colors, startangle=90, textprops={'fontsize': 9}
    )
    ax1.set_title('LDA Topic Distribution Ratio', fontsize=14, fontweight='bold')

    # æ¡å½¢å›¾
    bars = ax2.bar(topic_counts.index, topic_counts.values, color=colors)
    ax2.set_title('Number of Samples per Topic', fontsize=14, fontweight='bold')
    ax2.set_xlabel('Topic ID', fontsize=12)
    ax2.set_ylabel('Sample Count', fontsize=12)
    ax2.set_xticks(topic_counts.index)
    ax2.set_xticklabels([f"Topic {i}" for i in topic_counts.index])

    # åœ¨æ¡å½¢å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, count in zip(bars, topic_counts.values):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width() / 2., height + 50,
                 f'{count:,}', ha='center', va='bottom', fontsize=10)

    plt.tight_layout()
    plt.savefig('1_topic_distribution.png', dpi=150, bbox_inches='tight')
    print("ðŸ“Š ä¸»é¢˜åˆ†å¸ƒå›¾å·²ä¿å­˜ï¼š1_topic_distribution.png")


def plot_topic_sentiment_boxplot():
    """2. å„ä¸»é¢˜æƒ…æ„Ÿåˆ†æ•°åˆ†å¸ƒï¼ˆç®±çº¿å›¾ï¼‰"""
    fig, ax = plt.subplots(1, 1, figsize=(14, 7))

    # æŒ‰ä¸»é¢˜åˆ†ç»„çš„æƒ…æ„Ÿåˆ†æ•°ç®±çº¿å›¾
    box_data = [df[df['lda_topic'] == i]['sentiment_compound'].values for i in range(10)]
    box_plot = ax.boxplot(
        box_data, labels=[f"Topic {i}" for i in range(10)],
        patch_artist=True, showfliers=False  # éšè—å¼‚å¸¸å€¼ï¼Œæ›´æ¸…æ™°
    )

    # è®¾ç½®ç®±çº¿å›¾é¢œè‰²
    colors = plt.cm.RdYlBu_r(np.linspace(0.2, 0.8, 10))
    for patch, color in zip(box_plot['boxes'], colors):
        patch.set_facecolor(color)

    # æ·»åŠ å‚è€ƒçº¿ï¼ˆ0åˆ†ï¼šä¸­æ€§åŸºå‡†ï¼‰
    ax.axhline(y=0, color='red', linestyle='--', linewidth=1, label='Neutral Baseline (0 Score)')

    ax.set_title('Sentiment Score Distribution by Topic (Compound Score: -1 Negative ~ +1 Positive)', fontsize=14, fontweight='bold')
    ax.set_xlabel('Topic ID', fontsize=12)
    ax.set_ylabel('Sentiment Compound Score', fontsize=12)
    ax.legend()
    ax.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    plt.savefig('2_topic_sentiment_boxplot.png', dpi=150, bbox_inches='tight')
    print("ðŸ“Š ä¸»é¢˜-æƒ…æ„Ÿç®±çº¿å›¾å·²ä¿å­˜ï¼š2_topic_sentiment_boxplot.png")


def plot_topic_sentiment_heatmap():
    """3. ä¸»é¢˜-æƒ…æ„Ÿæžæ€§äº¤å‰çƒ­åŠ›å›¾ï¼ˆç»Ÿè®¡å„ä¸»é¢˜çš„æƒ…æ„Ÿæžæ€§å æ¯”ï¼‰"""
    # æž„å»ºäº¤å‰è¡¨ï¼šä¸»é¢˜ Ã— æƒ…æ„Ÿæžæ€§ï¼ˆä½¿ç”¨è‹±æ–‡æ ‡ç­¾ï¼‰
    cross_tab = pd.crosstab(df['lda_topic'], df['sentiment_polarity'], normalize='index') * 100  # æŒ‰ä¸»é¢˜å½’ä¸€åŒ–ï¼ˆç™¾åˆ†æ¯”ï¼‰
    cross_tab = cross_tab[['positive', 'neutral', 'negative']]  # è°ƒæ•´åˆ—é¡ºåºä¸ºè‹±æ–‡

    # ç»˜åˆ¶çƒ­åŠ›å›¾
    fig, ax = plt.subplots(1, 1, figsize=(12, 8))
    sns_heatmap = sb.heatmap(
        cross_tab, annot=True, fmt='.1f', cmap='RdYlGn_r',
        ax=ax, cbar_kws={'label': 'Percentage (%)'},
        annot_kws={'fontsize': 10}
    )

    ax.set_title('Sentiment Polarity Distribution Heatmap by Topic', fontsize=14, fontweight='bold')
    ax.set_xlabel('Sentiment Polarity', fontsize=12)
    ax.set_ylabel('Topic ID', fontsize=12)
    ax.set_yticklabels([f"Topic {i}" for i in cross_tab.index], rotation=0)

    plt.tight_layout()
    plt.savefig('3_topic_sentiment_heatmap.png', dpi=150, bbox_inches='tight')
    print("ðŸ“Š ä¸»é¢˜-æƒ…æ„Ÿçƒ­åŠ›å›¾å·²ä¿å­˜ï¼š3_topic_sentiment_heatmap.png")


def plot_temporal_topic_trend():
    """4. ä¸»é¢˜æ—¶é—´è¶‹åŠ¿ï¼ˆæŒ‰å¹´/æœˆç»Ÿè®¡å„ä¸»é¢˜å‘å¸ƒæ•°é‡ï¼‰"""
    # æŒ‰å¹´-ä¸»é¢˜ç»Ÿè®¡æ•°é‡
    yearly_topic = df.groupby(['year', 'lda_topic']).size().unstack(fill_value=0)

    # ç»˜åˆ¶å †å é¢ç§¯å›¾
    fig, ax = plt.subplots(1, 1, figsize=(14, 7))

    colors = plt.cm.tab10(np.linspace(0, 1, 10))
    yearly_topic.plot.area(
        ax=ax, stacked=True, color=colors, alpha=0.7,
        linewidth=1
    )

    ax.set_title('Annual Publication Trend by Topic', fontsize=14, fontweight='bold')
    ax.set_xlabel('Year', fontsize=12)
    ax.set_ylabel('Number of Publications', fontsize=12)
    ax.legend(title='Topic ID', bbox_to_anchor=(1.05, 1), loc='upper left')
    ax.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    plt.savefig('4_temporal_topic_trend.png', dpi=150, bbox_inches='tight')
    print("ðŸ“Š ä¸»é¢˜æ—¶é—´è¶‹åŠ¿å›¾å·²ä¿å­˜ï¼š4_temporal_topic_trend.png")


def plot_temporal_sentiment_trend():
    """5. æƒ…æ„Ÿæ—¶é—´è¶‹åŠ¿ï¼ˆæŒ‰å¹´ç»Ÿè®¡å¹³å‡æƒ…æ„Ÿåˆ†æ•°ï¼‰"""
    # æŒ‰å¹´ç»Ÿè®¡å¹³å‡æƒ…æ„Ÿåˆ†æ•°
    yearly_sentiment = df.groupby('year')['sentiment_compound'].agg(['mean', 'std']).reset_index()

    fig, ax = plt.subplots(1, 1, figsize=(12, 6))

    # ç»˜åˆ¶å¸¦è¯¯å·®æ¡çš„æŠ˜çº¿å›¾
    ax.errorbar(
        yearly_sentiment['year'], yearly_sentiment['mean'],
        yerr=yearly_sentiment['std'] / np.sqrt(len(df) / len(yearly_sentiment)),  # æ ‡å‡†è¯¯
        fmt='o-', linewidth=2, markersize=6, color='darkblue',
        ecolor='lightblue', capsize=5, label='Average Sentiment Score'
    )

    # æ·»åŠ ä¸­æ€§åŸºå‡†çº¿
    ax.axhline(y=0, color='red', linestyle='--', linewidth=1, label='Neutral Baseline')

    ax.set_title('Annual Average Sentiment Score Trend (Error Bars = Standard Error)', fontsize=14, fontweight='bold')
    ax.set_xlabel('Year', fontsize=12)
    ax.set_ylabel('Average Sentiment Compound Score', fontsize=12)
    ax.legend()
    ax.grid(alpha=0.3)

    plt.tight_layout()
    plt.savefig('5_temporal_sentiment_trend.png', dpi=150, bbox_inches='tight')
    print("ðŸ“Š æƒ…æ„Ÿæ—¶é—´è¶‹åŠ¿å›¾å·²ä¿å­˜ï¼š5_temporal_sentiment_trend.png")


def plot_topic_wordcloud():
    """6. å„ä¸»é¢˜å…³é”®è¯è¯äº‘ï¼ˆæ¯ä¸ªä¸»é¢˜ç”Ÿæˆä¸€ä¸ªè¯äº‘ï¼‰"""
    # åˆ›å»º2Ã—5çš„å­å›¾å¸ƒå±€
    fig, axes = plt.subplots(2, 5, figsize=(20, 8))
    axes = axes.flatten()  # å±•å¹³ä¸ºä¸€ç»´æ•°ç»„ï¼Œæ–¹ä¾¿å¾ªçŽ¯

    colors_list = list(mcolors.TABLEAU_COLORS.values())  # é¢œè‰²åˆ—è¡¨

    for topic_idx, ax in enumerate(axes):
        # èŽ·å–å½“å‰ä¸»é¢˜çš„æ‰€æœ‰æ–‡æœ¬
        topic_text = ' '.join(df[df['lda_topic'] == topic_idx]['headline_text'].tolist())

        # ç”Ÿæˆè¯äº‘
        wordcloud = WordCloud(
            width=400, height=300,
            background_color='white',
            max_words=50,
            colormap='viridis',
            stopwords=set(stopwords.words('english')),
            font_path=None  # è‹±æ–‡æ— éœ€æŒ‡å®šå­—ä½“
        ).generate(topic_text)

        # æ˜¾ç¤ºè¯äº‘
        ax.imshow(wordcloud, interpolation='bilinear')
        ax.axis('off')
        ax.set_title(f'Topic {topic_idx}\n{topic_keywords[topic_idx]}', fontsize=10, pad=10)

    plt.tight_layout()
    plt.savefig('6_topic_wordcloud.png', dpi=150, bbox_inches='tight')
    print("ðŸ“Š ä¸»é¢˜è¯äº‘å›¾å·²ä¿å­˜ï¼š6_topic_wordcloud.png")


def plot_sentiment_wordcloud():
    """7. æƒ…æ„Ÿæžæ€§å…³é”®è¯è¯äº‘ï¼ˆæ­£å‘/è´Ÿå‘/ä¸­æ€§å¯¹æ¯”ï¼‰"""
    # æŒ‰æƒ…æ„Ÿæžæ€§åˆ†ç»„æ–‡æœ¬
    pos_text = ' '.join(df[df['sentiment_polarity'] == 'positive']['headline_text'].tolist())
    neg_text = ' '.join(df[df['sentiment_polarity'] == 'negative']['headline_text'].tolist())
    neu_text = ' '.join(df[df['sentiment_polarity'] == 'neutral']['headline_text'].tolist())

    # åˆ›å»º1Ã—3çš„å­å›¾
    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))

    # å®šä¹‰è¯äº‘å‚æ•°
    wc_params = {
        'width': 500, 'height': 400,
        'background_color': 'white',
        'max_words': 80,
        'stopwords': set(stopwords.words('english')),
        'font_path': None
    }

    # æ­£å‘è¯äº‘ï¼ˆç»¿è‰²ç³»ï¼‰
    WordCloud(colormap='Greens', **wc_params).generate(pos_text).to_image()
    ax1.imshow(WordCloud(colormap='Greens', **wc_params).generate(pos_text), interpolation='bilinear')
    ax1.axis('off')
    ax1.set_title('Positive Sentiment Keywords', fontsize=12, fontweight='bold')

    # ä¸­æ€§è¯äº‘ï¼ˆç°è‰²ç³»ï¼‰
    ax2.imshow(WordCloud(colormap='Greys', **wc_params).generate(neu_text), interpolation='bilinear')
    ax2.axis('off')
    ax2.set_title('Neutral Sentiment Keywords', fontsize=12, fontweight='bold')

    # è´Ÿå‘è¯äº‘ï¼ˆçº¢è‰²ç³»ï¼‰
    ax3.imshow(WordCloud(colormap='Reds', **wc_params).generate(neg_text), interpolation='bilinear')
    ax3.axis('off')
    ax3.set_title('Negative Sentiment Keywords', fontsize=12, fontweight='bold')

    plt.tight_layout()
    plt.savefig('7_sentiment_wordcloud.png', dpi=150, bbox_inches='tight')
    print("ðŸ“Š æƒ…æ„Ÿå…³é”®è¯è¯äº‘å›¾å·²ä¿å­˜ï¼š7_sentiment_wordcloud.png")


def plot_topic_sentiment_histogram():
    """8. å„ä¸»é¢˜æƒ…æ„Ÿåˆ†æ•°ç›´æ–¹å›¾ï¼ˆå¯¹æ¯”åˆ†å¸ƒå·®å¼‚ï¼‰"""
    fig, axes = plt.subplots(2, 5, figsize=(20, 8))
    axes = axes.flatten()

    colors = plt.cm.viridis(np.linspace(0.2, 0.8, 10))

    for topic_idx, ax in enumerate(axes):
        # èŽ·å–å½“å‰ä¸»é¢˜çš„æƒ…æ„Ÿåˆ†æ•°
        sentiment_scores = df[df['lda_topic'] == topic_idx]['sentiment_compound']

        # ç»˜åˆ¶ç›´æ–¹å›¾
        ax.hist(
            sentiment_scores, bins=20, color=colors[topic_idx],
            alpha=0.7, edgecolor='black', linewidth=0.5
        )

        # æ·»åŠ å‡å€¼çº¿
        mean_score = sentiment_scores.mean()
        ax.axvline(mean_score, color='red', linestyle='--', linewidth=1,
                   label=f'Mean: {mean_score:.3f}')

        ax.set_title(f'Topic {topic_idx}', fontsize=10)
        ax.set_xlabel('Sentiment Score', fontsize=8)
        ax.set_ylabel('Frequency', fontsize=8)
        ax.legend(fontsize=8)
        ax.grid(alpha=0.3)

    plt.tight_layout()
    plt.savefig('8_topic_sentiment_histogram.png', dpi=150, bbox_inches='tight')
    print("ðŸ“Š ä¸»é¢˜æƒ…æ„Ÿåˆ†æ•°ç›´æ–¹å›¾å·²ä¿å­˜ï¼š8_topic_sentiment_histogram.png")


# ===================== 3. æ‰§è¡Œæ‰€æœ‰å¯è§†åŒ– =====================
if __name__ == "__main__":
    # å¯¼å…¥å¿…è¦çš„é¢å¤–åº“ï¼ˆä¹‹å‰ä»£ç ä¸­å·²ä¸‹è½½stopwordsï¼‰
    import nltk
    from nltk.corpus import stopwords

    nltk.download('stopwords', quiet=True)

    # ä¾æ¬¡æ‰§è¡Œå¯è§†åŒ–å‡½æ•°
    plot_topic_distribution()
    plot_topic_sentiment_boxplot()
    plot_topic_sentiment_heatmap()
    plot_temporal_topic_trend()
    plot_temporal_sentiment_trend()
    plot_topic_wordcloud()
    plot_sentiment_wordcloud()
    plot_topic_sentiment_histogram()

    print("\nðŸŽ‰ æ‰€æœ‰å¯è§†åŒ–åˆ†æžå®Œæˆï¼å…±ç”Ÿæˆ 8 å¼ å›¾è¡¨ï¼š")
    print("1. 1_topic_distribution.png - Topic Distribution (Pie + Bar Chart)")
    print("2. 2_topic_sentiment_boxplot.png - Topic-Sentiment Boxplot")
    print("3. 3_topic_sentiment_heatmap.png - Topic-Sentiment Heatmap")
    print("4. 4_temporal_topic_trend.png - Temporal Topic Trend Chart")
    print("5. 5_temporal_sentiment_trend.png - Temporal Sentiment Trend Chart")
    print("6. 6_topic_wordcloud.png - Topic Wordclouds")
    print("7. 7_sentiment_wordcloud.png - Sentiment Polarity Wordclouds")
    print("8. 8_topic_sentiment_histogram.png - Topic Sentiment Score Histograms")