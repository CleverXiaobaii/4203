# ===================== å‡æ–°é—»ç‡ r ä¸è€¸äººå¬é—»æŒ‡æ•° s çš„æ•°å­¦å…³ç³»æ‹Ÿåˆ =====================
# æŒ‰ s çš„ 0.1 åŒºé—´åˆ†ç»„ï¼Œæ‹Ÿåˆä¸‰ç§æ•°å­¦æ¨¡å‹ï¼ˆçº¿æ€§ã€å¯¹æ•°ã€æŒ‡æ•°ï¼‰
# åŒ…å«ç›¸å…³ç³»æ•°è®¡ç®—å’Œå®Œæ•´å¯è§†åŒ–
# ç‰ˆæœ¬ï¼šv1.0

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit
from scipy.stats import pearsonr

np.random.seed(42)

plt.rcParams['figure.facecolor'] = 'white'
plt.rcParams['axes.facecolor'] = 'white'
plt.rcParams['axes.grid'] = True
plt.rcParams['grid.alpha'] = 0.3
plt.style.use('seaborn-v0_8-whitegrid')


# ===================== 1. å®šä¹‰æ‹Ÿåˆå‡½æ•° =====================

# çº¿æ€§æ¨¡å‹ï¼šr = a * s + b
def linear_model(s, a, b):
    return a * s + b

# å¯¹æ•°æ¨¡å‹ï¼šr = a * log(b * s + c) + d
def log_model(s, a, b, c, d):
    return a * np.log(b * s + c) + d

# æŒ‡æ•°æ¨¡å‹ï¼šr = a * exp(b * s + c) + d
def exp_model(s, a, b, c, d):
    return a * np.exp(b * s + c) + d


def analyze_s_r_relation():
    """
    æŒ‰ s åŒºé—´åˆ†ç»„åˆ†æå‡æ–°é—»ç‡ r ä¸è€¸äººå¬é—»æŒ‡æ•° s çš„å…³ç³»
    """
    
    print("\n" + "=" * 90)
    print("ğŸ“Š å‡æ–°é—»ç‡ r ä¸è€¸äººå¬é—»æŒ‡æ•° s çš„æ•°å­¦å…³ç³»åˆ†æ")
    print("   æŒ‰ 0.1 åŒºé—´åˆ†ç»„ | æ‹Ÿåˆä¸‰ç§æ•°å­¦æ¨¡å‹ | è®¡ç®—ç›¸å…³ç³»æ•°")
    print("=" * 90)

    # ===================== 2. è¯»å–æ•°æ® =====================
    
    try:
        # å°è¯•è¯»å–å®é™…æ•°æ®æ–‡ä»¶
        df_pred = pd.read_csv('fake_news_predictions_improved.csv')
        s_all = df_pred['sensationalism_score'].values.astype(float)
        fake_pred_rf = df_pred['fake_pred_rf'].values.astype(float)
        
        print(f"\nâœ… åŠ è½½å®é™…æ•°æ®ï¼š{len(df_pred):,} æ¡æ–°é—»")
        
    except FileNotFoundError:
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨æ¼”ç¤ºæ•°æ®
        print("\nâš ï¸  æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¼”ç¤º...")
        
        n_samples = 50000
        s_all = np.random.beta(2, 5, n_samples)
        r_true = 20 - 15 * s_all + 5 * s_all**2
        r_true = np.clip(r_true, 0, 100)
        noise = np.random.normal(0, 8, n_samples)
        fake_prob = np.clip(r_true + noise, 0, 100) / 100.0
        fake_pred_rf = (np.random.random(n_samples) < fake_prob).astype(int)
        
        print(f"\nâœ… ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼š{n_samples:,} æ¡æ–°é—»")
    
    # æ¸…æ´— NaN
    mask = ~np.isnan(s_all) & ~np.isnan(fake_pred_rf)
    s_all = s_all[mask]
    fake_pred_rf = fake_pred_rf[mask]
    
    print(f"   s èŒƒå›´ï¼š[{s_all.min():.4f}, {s_all.max():.4f}]")
    print(f"   å‡æ–°é—»æ€»æ¯”ä¾‹ï¼š{np.mean(fake_pred_rf)*100:.2f}%")

    # ===================== 3. æŒ‰ s åŒºé—´åˆ†ç»„ =====================
    
    print(f"\nã€åˆ†ç»„è®¾ç½®ã€‘")
    bin_width = 0.05
    bin_start = int(np.floor(s_all.min() / bin_width)) * bin_width
    bin_end = int(np.ceil(s_all.max() / bin_width)) * bin_width
    bins = np.arange(bin_start, bin_end + bin_width, bin_width)
    
    print(f"   èŒƒå›´ï¼š[{bin_start:.2f}, {bin_end:.2f}]ï¼Œæ­¥é•¿ï¼š{bin_width}")
    print(f"   æ€»å…± {len(bins)-1} ä¸ªåŒºé—´")
    
    bin_indices = np.digitize(s_all, bins) - 1
    
    # è®¡ç®—æ¯ä¸ª bin çš„ç»Ÿè®¡
    bin_data = []
    for i in range(len(bins) - 1):
        mask_bin = (bin_indices == i)
        if np.sum(mask_bin) > 0:
            s_mid = (bins[i] + bins[i+1]) / 2.0
            r_bin = np.mean(fake_pred_rf[mask_bin]) * 100.0
            count_bin = np.sum(mask_bin)
            
            bin_data.append({
                's_bin': s_mid,
                'r_bin': r_bin,
                'count': count_bin,
                'bin_left': bins[i],
                'bin_right': bins[i+1]
            })
    
    bin_df = pd.DataFrame(bin_data)
    s = bin_df['s_bin'].values
    r = bin_df['r_bin'].values
    
    print(f"\nâœ… åˆ†ç»„å®Œæˆï¼š{len(bin_df)} ä¸ªéç©ºåŒºé—´\n")
    
    # æ‰“å°åˆ†ç»„ç»Ÿè®¡è¡¨
    result_table = bin_df[['bin_left', 'bin_right', 's_bin', 'r_bin', 'count']].copy()
    result_table.columns = ['Binå·¦ç«¯ç‚¹', 'Binå³ç«¯ç‚¹', 'såŒºé—´ä¸­ç‚¹', 'rå‡æ–°é—»ç‡%', 'æ ·æœ¬æ•°']
    result_table['æ ·æœ¬å æ¯”%'] = (result_table['æ ·æœ¬æ•°'] / result_table['æ ·æœ¬æ•°'].sum() * 100).round(2)
    
    print("=" * 100)
    print("ã€åˆ†ç»„ç»Ÿè®¡è¡¨ã€‘æŒ‰ s çš„ 0.1 åŒºé—´åˆ†ç»„")
    print("=" * 100)
    print(result_table.to_string(index=False))
    print("=" * 100)

    # ===================== 4. ç›¸å…³ç³»æ•°è®¡ç®— =====================
    
    pearson_r, p_value = pearsonr(s, r)
    
    print(f"\nã€Pearson ç›¸å…³ç³»æ•°ã€‘")
    print(f"   r = {pearson_r:.4f}")
    print(f"   p-value = {p_value:.4f}")
    print(f"   ç»“è®º = {'âœ“ æ˜¾è‘—ç›¸å…³ (p < 0.05)' if p_value < 0.05 else 'âœ— ä¸æ˜¾è‘— (p â‰¥ 0.05)'}")

    # ===================== 5. ä¸‰ç§æ¨¡å‹æ‹Ÿåˆ =====================
    
    print(f"\nã€æ¨¡å‹æ‹Ÿåˆã€‘")
    
    results = []
    
    # 5.1 çº¿æ€§æ¨¡å‹
    try:
        popt_lin, _ = curve_fit(linear_model, s, r)
        a_lin, b_lin = popt_lin
        r_pred_lin = linear_model(s, a_lin, b_lin)
        r2_lin = 1 - np.sum((r - r_pred_lin) ** 2) / np.sum((r - r.mean()) ** 2)
        rmse_lin = np.sqrt(np.mean((r - r_pred_lin) ** 2))
        lin_ok = True
        
        print(f"\nâœ“ çº¿æ€§æ¨¡å‹æ‹ŸåˆæˆåŠŸ")
        print(f"   å…¬å¼ï¼šr = {a_lin:.6f}Â·s + {b_lin:.6f}")
        print(f"   RÂ² = {r2_lin:.4f}ï¼ŒRMSE = {rmse_lin:.4f}")
        
        results.append({
            'æ¨¡å‹': 'çº¿æ€§',
            'å…¬å¼': f'r = {a_lin:.6f}Â·s + {b_lin:.6f}',
            'RÂ²': f'{r2_lin:.4f}',
            'RMSE': f'{rmse_lin:.4f}'
        })
    except Exception as e:
        print(f"\nâœ— çº¿æ€§æ¨¡å‹æ‹Ÿåˆå¤±è´¥ï¼š{e}")
        lin_ok = False

    # 5.2 å¯¹æ•°æ¨¡å‹
    a0, b0, c0, d0 = 1.0, 1.0, 1e-3, r.mean()
    bounds_log = ([-np.inf, 1e-6, 1e-6, -np.inf], [ np.inf,  np.inf,  np.inf,  np.inf])
    try:
        popt_log, _ = curve_fit(log_model, s, r, p0=[a0, b0, c0, d0], bounds=bounds_log, maxfev=10000)
        a_log, b_log, c_log, d_log = popt_log
        r_pred_log = log_model(s, a_log, b_log, c_log, d_log)
        r2_log = 1 - np.sum((r - r_pred_log) ** 2) / np.sum((r - r.mean()) ** 2)
        rmse_log = np.sqrt(np.mean((r - r_pred_log) ** 2))
        log_ok = True
        
        print(f"\nâœ“ å¯¹æ•°æ¨¡å‹æ‹ŸåˆæˆåŠŸ")
        print(f"   å…¬å¼ï¼šr = {a_log:.6f}Â·ln({b_log:.6f}Â·s + {c_log:.6f}) + {d_log:.6f}")
        print(f"   RÂ² = {r2_log:.4f}ï¼ŒRMSE = {rmse_log:.4f}")
        
        results.append({
            'æ¨¡å‹': 'å¯¹æ•°',
            'å…¬å¼': f'r = {a_log:.6f}Â·ln({b_log:.6f}Â·s + {c_log:.6f}) + {d_log:.6f}',
            'RÂ²': f'{r2_log:.4f}',
            'RMSE': f'{rmse_log:.4f}'
        })
    except Exception as e:
        print(f"\nâœ— å¯¹æ•°æ¨¡å‹æ‹Ÿåˆå¤±è´¥ï¼š{e}")
        log_ok = False

    # 5.3 æŒ‡æ•°æ¨¡å‹
    try:
        popt_exp, _ = curve_fit(exp_model, s, r, p0=[1.0, 1.0, 0.0, r.mean()], maxfev=10000)
        a_exp, b_exp, c_exp, d_exp = popt_exp
        r_pred_exp = exp_model(s, a_exp, b_exp, c_exp, d_exp)
        r2_exp = 1 - np.sum((r - r_pred_exp) ** 2) / np.sum((r - r.mean()) ** 2)
        rmse_exp = np.sqrt(np.mean((r - r_pred_exp) ** 2))
        exp_ok = True
        
        print(f"\nâœ“ æŒ‡æ•°æ¨¡å‹æ‹ŸåˆæˆåŠŸ")
        print(f"   å…¬å¼ï¼šr = {a_exp:.6f}Â·exp({b_exp:.6f}Â·s + {c_exp:.6f}) + {d_exp:.6f}")
        print(f"   RÂ² = {r2_exp:.4f}ï¼ŒRMSE = {rmse_exp:.4f}")
        
        results.append({
            'æ¨¡å‹': 'æŒ‡æ•°',
            'å…¬å¼': f'r = {a_exp:.6f}Â·exp({b_exp:.6f}Â·s + {c_exp:.6f}) + {d_exp:.6f}',
            'RÂ²': f'{r2_exp:.4f}',
            'RMSE': f'{rmse_exp:.4f}'
        })
    except Exception as e:
        print(f"\nâœ— æŒ‡æ•°æ¨¡å‹æ‹Ÿåˆå¤±è´¥ï¼š{e}")
        exp_ok = False

    # æ‰“å°æ¨¡å‹å¯¹æ¯”è¡¨
    results_df = pd.DataFrame(results)
    print("\n" + "=" * 140)
    print("ã€ä¸‰ç§æ¨¡å‹æ‹Ÿåˆç»“æœå¯¹æ¯”ã€‘")
    print("=" * 140)
    print(results_df.to_string(index=False))
    print("=" * 140)
    
    # æ‰¾æœ€ä½³æ¨¡å‹
    if lin_ok and log_ok and exp_ok:
        r2_values = [r2_lin, r2_log, r2_exp]
        best_idx = np.argmax(r2_values)
        models = ['çº¿æ€§', 'å¯¹æ•°', 'æŒ‡æ•°']
        best_r2 = r2_values[best_idx]
        print(f"\nã€æœ€ä½³æ‹Ÿåˆæ¨¡å‹ã€‘ï¼š{models[best_idx]} (RÂ² = {best_r2:.4f})\n")

    # ===================== 6. ç»˜åˆ¶å›¾è¡¨ =====================
    
    fig, ax = plt.subplots(figsize=(13, 8))

    # æ•£ç‚¹ï¼ˆç‚¹å¤§å°æŒ‰æ ·æœ¬é‡ï¼‰
    scatter = ax.scatter(
        bin_df['s_bin'], bin_df['r_bin'],
        #s=bin_df['count']/10,
        color='#34495E',
        edgecolor='black',
        alpha=0.7,
        label=f'Binned Data',
        zorder=3
    )

    s_line = np.linspace(s.min() - 0.02, s.max() + 0.02, 300)

    # ç»˜åˆ¶æ‹Ÿåˆæ›²çº¿
    if lin_ok:
        ax.plot(
            s_line,
            linear_model(s_line, a_lin, b_lin),
            color='#E74C3C',
            linewidth=2.5,
            label=f'Linear: RÂ²={r2_lin:.4f}',
            zorder=2
        )

    if log_ok:
        ax.plot(
            s_line,
            log_model(s_line, a_log, b_log, c_log, d_log),
            color='#3498DB',
            linewidth=2.5,
            linestyle='--',
            label=f'Log: RÂ²={r2_log:.4f}',
            zorder=2
        )

    if exp_ok:
        ax.plot(
            s_line,
            exp_model(s_line, a_exp, b_exp, c_exp, d_exp),
            color='#27AE60',
            linewidth=2.5,
            linestyle='-.',
            label=f'Exp: RÂ²={r2_exp:.4f}',
            zorder=2
        )

    ax.set_xlabel('Sensationalism Score (s)', fontsize=13, fontweight='bold')
    ax.set_ylabel('Fake News Ratio (r, %)', fontsize=13, fontweight='bold')
    
    title_text = (
        f'Relationship between Sensationalism and Fake News Ratio\n'
        f'Binned by 0.1 intervals | Pearson r = {pearson_r:.4f}, p = {p_value:.4f} '
        f'{"(Significant)" if p_value < 0.05 else "(Not Significant)"}'
    )
    ax.set_title(title_text, fontsize=14, fontweight='bold', pad=15)
    
    ax.grid(True, alpha=0.3)
    ax.legend(fontsize=11, loc='best', framealpha=0.95)
    ax.set_xlim([s.min() - 0.03, s.max() + 0.03])

    plt.tight_layout()
    plt.savefig('fake_news_s_r_relation_binned.png', dpi=200, bbox_inches='tight', facecolor='white')
    print("âœ… å›¾è¡¨å·²ä¿å­˜ï¼šfake_news_s_r_relation_binned.png\n")
    plt.show()
    
    # ä¿å­˜ç»Ÿè®¡è¡¨
    result_table.to_csv('fake_news_s_r_binned_analysis.csv', index=False)
    print("âœ… ç»Ÿè®¡è¡¨å·²ä¿å­˜ï¼šfake_news_s_r_binned_analysis.csv\n")
    
    print("=" * 90 + "\n")


if __name__ == "__main__":
    analyze_s_r_relation()
